{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/naveenkumar/Dropbox (Personal)/OnlineWork/Notebooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delcaring all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection \n",
    "\n",
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundn(x,n):\n",
    "    from math import pow\n",
    "    return round(x*pow(10,n))/pow(10,n)\n",
    "\n",
    "def columntype(x):\n",
    "    t = ''\n",
    "    if is_numeric_dtype(x) == True:\n",
    "        t = 'numeric'\n",
    "    else:\n",
    "        t = 'string'\n",
    "    \n",
    "    return t\n",
    "\n",
    "def unique_value_counts(x,y,cut_off):\n",
    "    if y <= cut_off:\n",
    "        return (s2[x].value_counts()).to_dict()\n",
    "    \n",
    "    \n",
    "def replace_DDMMYY_WITH_DDMMYYYY(indate, AddCentury):\n",
    "    if len(str(indate)) == 8:\n",
    "        YY = str(indate)[6:8]\n",
    "        YY_INT = int(YY) + AddCentury\n",
    "        return str(indate)[0:6] + str(YY_INT)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def datediff(d1,d2,date_format):\n",
    "    df = date_format\n",
    "    a = datetime.strptime(str(d1), df)\n",
    "    b = datetime.strptime(str(d2), df)\n",
    "    delta = b - a\n",
    "    return delta.days\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "def ds_summary(s2):\n",
    "    cmd = pd.DataFrame(s2.columns,columns=['column_name'])\n",
    "    cmd['TotalRows'] = len(s2)\n",
    "    cmd['TotalUniqueLevels'] = cmd['column_name'].apply(lambda col:s2[col].nunique())\n",
    "    cmd['PercentUniqueValues'] = cmd['TotalUniqueLevels']/cmd['TotalRows']\n",
    "    cmd['TotalNullValues'] = cmd['column_name'].apply(lambda col:s2[col].isnull().sum())\n",
    "    cmd['PercentNullValues'] = cmd['TotalNullValues']/cmd['TotalRows']\n",
    "    cmd['IdColFlag'] = cmd['TotalRows'] == cmd['TotalUniqueLevels']\n",
    "    cmd['DataType'] = cmd['column_name'].apply(lambda col:columntype(s2[col]))\n",
    "    cmd['UniqueValue'] = cmd[cmd['TotalUniqueLevels'] < 11]['column_name'].apply(lambda col:(s2[col].value_counts()).to_dict())\n",
    "    cmd['mean'] = cmd[cmd['DataType']=='numeric']['column_name'].apply(lambda col:round(s2[col].mean(),2))\n",
    "    cmd['min'] = cmd[cmd['DataType']=='numeric']['column_name'].apply(lambda col:round(s2[col].min(),2))\n",
    "    cmd['q1'] = cmd[cmd['DataType']=='numeric']['column_name'].apply(lambda col:round(s2[col].quantile(q=0.25),2))\n",
    "    cmd['median'] = cmd[cmd['DataType']=='numeric']['column_name'].apply(lambda col:round(s2[col].median(),2))\n",
    "    cmd['q3'] = cmd[cmd['DataType']=='numeric']['column_name'].apply(lambda col:round(s2[col].quantile(q=0.75),2))\n",
    "    cmd['max'] = cmd[cmd['DataType']=='numeric']['column_name'].apply(lambda col:round(s2[col].max(),2))\n",
    "    return cmd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate information value\n",
    "def calc_iv(df, feature, target, pr=0):\n",
    "\n",
    "    lst = []\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature, val, df[df[feature] == val].count()[feature], df[(df[feature] == val) & (df[target] == 1)].count()[feature]])\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Bad'])\n",
    "    data = data[data['Bad'] > 0]\n",
    "\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "    data['ValIV'] = (data['WoE'] * (data['Distribution Good'] - data['Distribution Bad']))\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=True)\n",
    "\n",
    "    IV = data['ValIV'].sum()\n",
    "    \n",
    "    if pr == 1:\n",
    "        print(data)\n",
    "    \n",
    "    return IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_dist(x):\n",
    "    print(\"-----------------------------------\")\n",
    "    for t in np.arange(0.01,1.0,0.01):\n",
    "        print(str(t) + \" : \" + str(x.quantile(q=t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directories and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir = '/Users/naveenkumar/Dropbox/OnlineWork/Datasets/Titanic/input/'\n",
    "outputdir = '/Users/naveenkumar/Dropbox/OnlineWork/Datasets/Titanic/output/'\n",
    "\n",
    "trainf = 'train.csv'\n",
    "testf = 'test.csv'\n",
    "\n",
    "trainfpath = inputdir + trainf\n",
    "testfpath = inputdir + testf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(trainfpath)\n",
    "test = pd.read_csv(testfpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "t = train.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
