{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/naveenkumar/Dropbox/OnlineWork/mlusecase/Notebooks/Simility'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import dateutil\n",
    "import warnings\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.layers import Input, Embedding\n",
    "import hypertools as hyp\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import string\n",
    "\n",
    "import \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "wdir = \"/Users/naveenkumar/simility/quoka\"\n",
    "INSTANCES = os.path.join(wdir, \"quoka_uniq_filtered_cols.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate information value\n",
    "def calc_iv(df, feature, target, pr=0):\n",
    "\n",
    "    lst = []\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature, val, df[df[feature] == val].count()[feature], df[(df[feature] == val) & (df[target] == 1)].count()[feature]])\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Bad'])\n",
    "    data = data[data['Bad'] > 0]\n",
    "\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "    data['ValIV'] = (data['WoE'] * (data['Distribution Good'] - data['Distribution Bad']))\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=True)\n",
    "\n",
    "    IV = data['ValIV'].sum()\n",
    "    \n",
    "    if pr == 1:\n",
    "        print(data)\n",
    "    \n",
    "    return IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(INSTANCES,sep=',',header='infer',quotechar='\"', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OK'}                     343230\n",
      "{'SCORING_DELETE'}          13932\n",
      "{'OK','SCORING_DELETE'}       942\n",
      "{}                            213\n",
      "Name: sim_dc, dtype: int64\n",
      "358317\n",
      "358317\n"
     ]
    }
   ],
   "source": [
    "print(d['sim_dc'].value_counts())\n",
    "print(d['eid'].nunique())#4506988\n",
    "print(d.shape[0])#4506988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['y'] = np.where((d['sim_dc'] == \"{'SCORING_DELETE'}\") ,1,0)\n",
    "d['y'] = np.where((d['sim_dc'] == \"{'OK','SCORING_DELETE'}\"),1,d['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(d['sim_dc'], d['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    343443\n",
       "1     14874\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.drop('sim_dc', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_list = [0.01, 0.02, 0.05, 0.25, 0.50, 0.75, 0.95, 0.98, 0.99]\n",
    "x_d_allsummary = d.describe(percentiles=percentiles_list, include ='all').transpose()\n",
    "x_d_allsummary.reset_index(level=0, inplace=True)\n",
    "x_d_allsummary.rename(columns={'index': 'ColName'}, inplace=True)\n",
    "x_d_allsummary['DataType'] = x_d_allsummary['ColName'].apply(lambda col:d[col].dtype)\n",
    "x_d_allsummary['TotalNullValues'] = x_d_allsummary['ColName'].apply(lambda col:d[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    1442\n",
       "int64        21\n",
       "bool          3\n",
       "object        1\n",
       "Name: DataType, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_d_allsummary['DataType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ad_zipcode    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.dtypes[d.dtypes == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_list = [0.01, 0.02, 0.05, 0.25, 0.50, 0.75, 0.95, 0.98, 0.99]\n",
    "d_summ = d.describe(percentiles=percentiles_list, include ='all').transpose()\n",
    "d_summ.reset_index(level=0, inplace=True)\n",
    "d_summ.rename(columns={'index': 'ColName'}, inplace=True)\n",
    "d_summ['DataType'] = d_summ['ColName'].apply(lambda col:d[col].dtype)\n",
    "d_summ['TotalNullValues'] = d_summ['ColName'].apply(lambda col:d[col].isnull().sum())\n",
    "d_summ['TotalUniqueLevels'] = d_summ['ColName'].apply(lambda col:d[col].nunique())\n",
    "d_summ['PercentUniqueValues'] = d_summ['TotalUniqueLevels']/d_summ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IV computattion of object is under progess\n"
     ]
    }
   ],
   "source": [
    "def compute_iv_ds(df_in, target_col, n_quantile=5):\n",
    "    \n",
    "    y_d = d[target_col].to_frame()\n",
    "    \n",
    "    iv_df = pd.DataFrame()\n",
    "    \n",
    "    f_list = df_in.columns.tolist()\n",
    "    f_list.remove(target_col)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for f in f_list:\n",
    "        f_dtype = df_in[f].dtype.name\n",
    "        \n",
    "        if df_in[f].max() > df_in[f].min():\n",
    "            if re.sub(r'(float|int)[0-9]+', r'float', f_dtype) == 'float':\n",
    "        \n",
    "                tmp_df = pd.qcut(d[f], n_quantile, labels=None, retbins=False, precision=3, duplicates='drop').to_frame()\n",
    "                tmp_df = tmp_df.join(y_d)\n",
    "\n",
    "                iv_out = np.round(calc_iv(tmp_df, f, target_col),2)\n",
    "                \n",
    "                tmp_iv_df = pd.DataFrame({'feature' : [f],\n",
    "                                          'datatype' :[d[f].dtype],\n",
    "                                           'iv' : [iv_out]\n",
    "                                         })\n",
    "                iv_df = iv_df.append(tmp_iv_df)\n",
    "\n",
    "    \n",
    "            elif re.sub(r'.*bool.*', r'bool', f_dtype) == 'bool':\n",
    "\n",
    "                    tmp_df = d[f].to_frame()\n",
    "                    tmp_df = tmp_df.join(y_d)\n",
    "                    iv_out = np.round(calc_iv(tmp_df, f, target_col),2)\n",
    "\n",
    "                    tmp_iv_df = pd.DataFrame({'feature'  : [f],\n",
    "                                              'datatype' :[d[f].dtype],\n",
    "                                               'iv'      : [iv_out]\n",
    "                                             })\n",
    "\n",
    "                    iv_df = iv_df.append(tmp_iv_df)\n",
    "\n",
    "            else :\n",
    "                print('IV computattion of '+ f_dtype + ' is under progess')\n",
    "            \n",
    "    iv_df.reset_index()\n",
    "\n",
    "    return iv_df \n",
    "\n",
    "d_iv = compute_iv_ds(d, 'y',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=4, score_func=<function chi2 at 0x1a155928c0>)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "# load data\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# feature extraction\n",
    "\n",
    "SelectKBest(score_func=chi2, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
